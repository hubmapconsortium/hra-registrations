{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09a9afb5",
   "metadata": {},
   "source": [
    "# RUI Reporter - SenNet Analysis\n",
    "\n",
    "This notebook analyzes RUI location registration coverage for SenNet datasets using the SenNet APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc7436",
   "metadata": {},
   "source": [
    "## List of Supported Reference Organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897edce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Supported Reference Organs\n",
      "Extracted 42 unique UBERON IDs\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# HRA API endpoint for reference organs\n",
    "REFERENCE_ORGANS_URL = \"https://apps.humanatlas.io/api/v1/reference-organs\"\n",
    "\n",
    "# Get all reference organs\n",
    "response = requests.get(REFERENCE_ORGANS_URL)\n",
    "organs = response.json()\n",
    "\n",
    "# Extract and normalize the UBERON IDs from the API\n",
    "def iri_to_curie(iri):\n",
    "    if iri and \"obo/UBERON_\" in iri:\n",
    "        return \"UBERON:\" + iri.split(\"_\")[-1]\n",
    "    return iri\n",
    "\n",
    "reference_uberon_ids = {iri_to_curie(organ.get(\"representation_of\")) for organ in organs if organ.get(\"representation_of\")}\n",
    "\n",
    "print(f\"{len(organs)} Supported Reference Organs\")\n",
    "print(f\"Extracted {len(reference_uberon_ids)} unique UBERON IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c419ecd5",
   "metadata": {},
   "source": [
    "## Ratio of Registered/Total for SenNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f65520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1000 datasets so far...\n",
      "Fetched 2000 datasets so far...\n",
      "Fetched 2147 datasets so far...\n",
      "Total fetched: 2147 datasets\n",
      "Total datasets: 2147\n",
      "Supported datasets: 1466\n",
      "Registered datasets: 854\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# --- Setup reference organs ---\n",
    "# HRA API endpoint for reference organs\n",
    "REFERENCE_ORGANS_URL = \"https://apps.humanatlas.io/api/v1/reference-organs\"\n",
    "\n",
    "# Get all reference organs\n",
    "response = requests.get(REFERENCE_ORGANS_URL)\n",
    "organs = response.json()\n",
    "\n",
    "# Extract and normalize the UBERON IDs from the API\n",
    "def iri_to_curie(iri):\n",
    "    if iri and \"obo/UBERON_\" in iri:\n",
    "        return \"UBERON:\" + iri.split(\"_\")[-1]\n",
    "    return iri\n",
    "\n",
    "reference_uberon_ids = {iri_to_curie(organ.get(\"representation_of\")) for organ in organs if organ.get(\"representation_of\")}\n",
    "\n",
    "# --- User-provided SenNet API token ---\n",
    "SENNET_TOKEN = \"AgKKovd81aw6X1W9z0O5G0mMXyzln3zWja6qGE5dEXQwxyBOoHeC4Xo2Jkg6jOBed6kXB2xOBEPWXUDa61qOhb52Y6\"\n",
    "\n",
    "# SenNet API endpoints\n",
    "SEARCH_API_URL = \"https://search.api.sennetconsortium.org/search\"\n",
    "headers = {\"Authorization\": f\"Bearer {SENNET_TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Get total count of all datasets\n",
    "total_query = {\n",
    "    \"version\": True,\n",
    "    \"size\": 0,\n",
    "    \"track_total_hits\": True,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"filter\": [\n",
    "                {\"term\": {\"entity_type.keyword\": \"Dataset\"}},\n",
    "                {\"term\": {\"creation_action.keyword\": \"Create Dataset Activity\"}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "total_response = requests.post(SEARCH_API_URL, json=total_query, headers=headers)\n",
    "total_datasets_count = total_response.json()['hits']['total']['value'] if total_response.status_code == 200 else 0\n",
    "\n",
    "# Fetch ALL datasets using pagination\n",
    "all_datasets = []\n",
    "page_size = 1000  # Max page size\n",
    "from_offset = 0\n",
    "\n",
    "while True:\n",
    "    datasets_query = {\n",
    "        \"version\": True,\n",
    "        \"size\": page_size,\n",
    "        \"from\": from_offset,\n",
    "        \"_source\": [\"uuid\", \"sennet_id\", \"origin_samples.organ\", \"rui_location\", \"rui_locations\", \"ancestors.rui_location\"],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"filter\": [\n",
    "                    {\"term\": {\"entity_type.keyword\": \"Dataset\"}},\n",
    "                    {\"term\": {\"creation_action.keyword\": \"Create Dataset Activity\"}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    datasets_response = requests.post(SEARCH_API_URL, json=datasets_query, headers=headers)\n",
    "    \n",
    "    if datasets_response.status_code != 200:\n",
    "        print(f\"Error fetching datasets: {datasets_response.status_code}\")\n",
    "        break\n",
    "    \n",
    "    datasets_data = datasets_response.json()\n",
    "    datasets_batch = datasets_data.get('hits', {}).get('hits', [])\n",
    "    \n",
    "    if not datasets_batch:\n",
    "        break\n",
    "    \n",
    "    all_datasets.extend(datasets_batch)\n",
    "    from_offset += page_size\n",
    "    \n",
    "    print(f\"Fetched {len(all_datasets)} datasets so far...\")\n",
    "    \n",
    "    # Stop if we got fewer than page_size results (last page)\n",
    "    if len(datasets_batch) < page_size:\n",
    "        break\n",
    "\n",
    "print(f\"Total fetched: {len(all_datasets)} datasets\")\n",
    "\n",
    "# Cross-match ALL datasets with reference organs\n",
    "supported_count = 0\n",
    "registered_count = 0\n",
    "\n",
    "for dataset in all_datasets:\n",
    "    source = dataset.get('_source', {})\n",
    "    origin_samples = source.get('origin_samples', [])\n",
    "    \n",
    "    # Check if any origin_sample organ matches reference organs\n",
    "    is_supported = False\n",
    "    for sample in origin_samples:\n",
    "        organ = sample.get('organ')\n",
    "        if organ and organ in reference_uberon_ids:\n",
    "            is_supported = True\n",
    "            break\n",
    "    \n",
    "    if is_supported:\n",
    "        supported_count += 1\n",
    "        \n",
    "        # Check for RUI location data\n",
    "        has_rui_location = False\n",
    "        \n",
    "        # Check direct rui_location fields\n",
    "        if source.get('rui_location') or source.get('rui_locations'):\n",
    "            has_rui_location = True\n",
    "        \n",
    "        # Check ancestors array for rui_location\n",
    "        ancestors = source.get('ancestors', [])\n",
    "        for ancestor in ancestors:\n",
    "            if ancestor.get('rui_location') or ancestor.get('rui_locations'):\n",
    "                has_rui_location = True\n",
    "                break\n",
    "        \n",
    "        if has_rui_location:\n",
    "            registered_count += 1\n",
    "\n",
    "print(f\"Total datasets: {total_datasets_count}\")\n",
    "print(f\"Supported datasets: {supported_count}\")\n",
    "print(f\"Registered datasets: {registered_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
